{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick dynaprog test.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Uses the sequential dynamic programming function to find a proportional allocation\n",
    "of items to agents with different valuations, with a largest sum of utilities (utilitarian value).\n",
    "The input is a valuation-matrix v, where v[i][j] is the value of agent i to item j.\n",
    "The states are of the form  (v1, v2, ..., vn) where n is the number of agents.\n",
    "The \"vi\" are the value of bundle i to agent i.\n",
    "Programmer: Erel Segal-Halevi\n",
    "Since: 2021-12\n",
    "\"\"\"\n",
    "\n",
    "import dynprog\n",
    "from dynprog.sequential import SequentialDynamicProgram\n",
    "\n",
    "import math, logging\n",
    "from typing import *\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "####\n",
    "## COMMON BLOCK\n",
    "####\n",
    "\n",
    "def items_as_value_vectors(valuation_matrix):\n",
    "    \"\"\"\n",
    "    Convert a valuation matrix (an input to a fair division algorithm) into a list of value-vectors.\n",
    "    Each value-vector v represents an item: v[i] is the value of the item for agent i (i = 0,...,n-1).\n",
    "    The last element, v[n], is the item index.\n",
    "    >>> items_as_value_vectors([[11,22,33],[44,55,66]])\n",
    "    [[11, 44, 0], [22, 55, 1], [33, 66, 2]]\n",
    "    \"\"\"\n",
    "    num_of_agents   = len(valuation_matrix)\n",
    "    num_of_items    = len(valuation_matrix[0])\n",
    "    return [  # Each item is represented by a vector of values - a value for each agent. The last value is the item index.\n",
    "        [valuation_matrix[agent_index][item_index] for agent_index in range(num_of_agents)] + [item_index]\n",
    "        for item_index in range(num_of_items)\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "def add_input_to_bin_sum(bin_sums:list, bin_index:int, input:int):\n",
    "    \"\"\"\n",
    "    Adds the given input integer to bin #bin_index in the given list of bins.\n",
    "    >>> add_input_to_bin_sum([11, 22, 33], 0, 77)\n",
    "    (88, 22, 33)\n",
    "    >>> add_input_to_bin_sum([11, 22, 33], 1, 77)\n",
    "    (11, 99, 33)\n",
    "    >>> add_input_to_bin_sum([11, 22, 33], 2, 77)\n",
    "    (11, 22, 110)\n",
    "    \"\"\"\n",
    "    new_bin_sums = list(bin_sums)\n",
    "    new_bin_sums[bin_index] = new_bin_sums[bin_index] + input\n",
    "    return tuple(new_bin_sums)\n",
    "\n",
    "\n",
    "def add_input_to_agent_value(agent_values:list, agent_index:int, item_values:list):\n",
    "    \"\"\"\n",
    "    Update the state of a dynamic program by giving an item to a specific agent.\n",
    "    :param agent_values: the current vector of agent values, before adding the new item.\n",
    "    :param agent_index: the agent to which the item is given.\n",
    "    :param item_values: a list of values: input[i] represents the value of the current item for agent i.\n",
    "    >>> add_input_to_agent_value([11, 22, 33], 0, [55,66,77,1])\n",
    "    (66, 22, 33)\n",
    "    >>> add_input_to_agent_value([11, 22, 33], 1, [55,66,77,1])\n",
    "    (11, 88, 33)\n",
    "    >>> add_input_to_agent_value([11, 22, 33], 2, [55,66,77,1])\n",
    "    (11, 22, 110)\n",
    "    \"\"\"\n",
    "    return add_input_to_bin_sum(agent_values, agent_index, item_values[agent_index])\n",
    "\n",
    "\n",
    "def add_input_to_bin(bins:list, agent_index:int, item_index:int):\n",
    "    \"\"\"\n",
    "    Update the solution of a dynamic program by giving an item to a specific agent.\n",
    "    \n",
    "    :param bins: the current vector of agent bundles, before adding the new item.\n",
    "    :param agent_index: the agent to which the item is given.\n",
    "    :param item_index: the index of the given item.\n",
    "    Adds the given input integer to bin #agent_index in the given list of bins.\n",
    "    >>> add_input_to_bin([[11,22], [33,44], [55,66]], 1, 1)\n",
    "    [[11, 22], [33, 44, 1], [55, 66]]\n",
    "    \"\"\"\n",
    "    new_bins = list(bins)\n",
    "    new_bins[agent_index] = new_bins[agent_index]+[item_index]\n",
    "    return new_bins\n",
    "\n",
    "#### \n",
    "## UM within EF1 Code\n",
    "###\n",
    "\n",
    "\n",
    "def utilitarian_ef1_value(valuation_matrix, efx=False):\n",
    "    \"\"\"\n",
    "    Returns the maximum utilitarian value in a ef1 allocation - does *not* return the partition itself.\n",
    "    >>> dynprog.logger.setLevel(logging.WARNING)\n",
    "    >>> utilitarian_ef1_value([[11,0,11],[33,44,55]])\n",
    "    110.0\n",
    "    >>> utilitarian_ef1_value([[11,0,11],[33,44,55]],efx=True)\n",
    "    110.0\n",
    "    >>> utilitarian_ef1_value([[11,22,33,44],[44,33,22,11]])\n",
    "    154.0\n",
    "    >>> utilitarian_ef1_value([[11,22,33,44],[44,33,22,11]],efx=True)\n",
    "    154.0\n",
    "    >>> utilitarian_ef1_value([[11,0,11,11],[0,11,11,11],[33,33,33,33]])\n",
    "    88.0\n",
    "    >>> utilitarian_ef1_value([[11,0,11,11],[0,11,11,11],[33,33,33,33]],efx=True)\n",
    "    88.0\n",
    "    >>> utilitarian_ef1_value([[11],[22]])\n",
    "    22.0\n",
    "    >>> utilitarian_ef1_value([[11],[22]],efx=True)\n",
    "    22.0\n",
    "    >>> utilitarian_ef1_value([[98,91,29,50,76,94],[43,67,93,35,49,12],[45,10,62,47,82,60]])\n",
    "    505.0\n",
    "    >>> utilitarian_ef1_value([[98,91,29,50,76,94],[43,67,93,35,49,12],[45,10,62,47,82,60]],efx=True)\n",
    "    481.0\n",
    "    \"\"\"\n",
    "    items = items_as_value_vectors(valuation_matrix)\n",
    "    return EF1PartitionDP(valuation_matrix, efx).max_value(items)\n",
    "\n",
    "\n",
    "\n",
    "#### Dynamic program definition:\n",
    "\n",
    "\n",
    "class EF1PartitionDP(SequentialDynamicProgram):\n",
    "\n",
    "    # The states are of the form (d11, d12, ..., dnn; b11, b12, ..., bnn) where n is the number of agents.\n",
    "    # where dij := vi(Ai)-vi(Aj).\n",
    "    # and   bij is the largest value for i of an item allocated to j.\n",
    "\n",
    "    def __init__(self, valuation_matrix, efx=False):\n",
    "        num_of_agents = self.num_of_agents = len(valuation_matrix)\n",
    "        self.thresholds = [\n",
    "            sum(valuation_matrix[i]) / num_of_agents\n",
    "            for i in range(num_of_agents)\n",
    "        ]\n",
    "        self.valuation_matrix = valuation_matrix\n",
    "        self.sum_valuation_matrix = sum(map(sum, valuation_matrix))\n",
    "        self.efx = efx\n",
    "\n",
    "    def initial_states(self):\n",
    "        zero_differences = self.num_of_agents * (self.num_of_agents * (0,),)\n",
    "        # print(\"zero_differences\",zero_differences)\n",
    "        initial_value_to_remove = math.inf if self.efx else 0\n",
    "        largest_value_owned_by_others = self.num_of_agents * (\n",
    "            self.num_of_agents * (initial_value_to_remove,),\n",
    "        )\n",
    "        return {(zero_differences, largest_value_owned_by_others)}\n",
    "\n",
    "    def initial_solution(self):\n",
    "        empty_bundles = [[] for _ in range(self.num_of_agents)]\n",
    "        return empty_bundles\n",
    "\n",
    "    def transition_functions(self):\n",
    "        return [\n",
    "            lambda state, input, agent_index=agent_index: (\n",
    "                _EF1_update_bundle_differences(state[0], agent_index, input),\n",
    "                _EF1_update_value_owned_by_others(\n",
    "                    state[1],\n",
    "                    agent_index,\n",
    "                    input[-1],\n",
    "                    self.valuation_matrix,\n",
    "                    self.efx,\n",
    "                ),\n",
    "            )\n",
    "            for agent_index in range(self.num_of_agents)\n",
    "        ]\n",
    "\n",
    "    def construction_functions(self):\n",
    "        return [\n",
    "            lambda solution, input, agent_index=agent_index: add_input_to_bin(\n",
    "                solution, agent_index, input[-1]\n",
    "            )\n",
    "            for agent_index in range(self.num_of_agents)\n",
    "        ]\n",
    "\n",
    "    def value_function(self):\n",
    "        return (\n",
    "            lambda state: (sum(map(sum, state[0])) + self.sum_valuation_matrix)\n",
    "            / self.num_of_agents\n",
    "            if self._is_ef1(state[0], state[1])\n",
    "            else -math.inf\n",
    "        )\n",
    "\n",
    "    def _is_ef1(\n",
    "        self, bundle_differences: list, largest_value_owned_by_others: list\n",
    "    ) -> bool:\n",
    "        return all(\n",
    "            [\n",
    "                bundle_differences[i][j] + largest_value_owned_by_others[i][j]\n",
    "                >= 0\n",
    "                for i in range(self.num_of_agents)\n",
    "                for j in range(self.num_of_agents)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "def _EF1_update_bundle_differences(bundle_differences, agent_index, item_values):\n",
    "    \"\"\"\n",
    "    >>> _update_bundle_differences( ((0,0),(0,0)), 0, [11,33,0]  )\n",
    "    ((0, 11), (-33, 0))\n",
    "    >>> _update_bundle_differences( ((0,0),(0,0)), 1, [11,33,0]  )\n",
    "    ((0, -11), (33, 0))\n",
    "    \"\"\"\n",
    "    # print(\"bundle_differences\",bundle_differences)\n",
    "    num_of_agents = len(bundle_differences)\n",
    "    new_bundle_differences = [list(d) for d in bundle_differences]\n",
    "    for other_agent_index in range(num_of_agents):\n",
    "        if other_agent_index == agent_index:\n",
    "            continue\n",
    "        new_bundle_differences[agent_index][other_agent_index] += item_values[\n",
    "            agent_index\n",
    "        ]\n",
    "        new_bundle_differences[other_agent_index][agent_index] -= item_values[\n",
    "            other_agent_index\n",
    "        ]\n",
    "    new_bundle_differences = tuple((tuple(d) for d in new_bundle_differences))\n",
    "    return new_bundle_differences\n",
    "\n",
    "\n",
    "def _EF1_update_value_owned_by_others(\n",
    "    largest_value_owned_by_others: list,\n",
    "    agent_index: int,\n",
    "    item_index: int,\n",
    "    valuation_matrix,\n",
    "    efx=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Update the matrix of largest-value-owned-by-others when\n",
    "    the item #item_index is given to the agent #agent_index.\n",
    "    >>> _update_value_owned_by_others([[0,0,0],[0,0,0],[0,0,0]], 0, 0, [[55,66,77],[88,99,11],[22,33,44]])\n",
    "    ((0, 0, 0), (88, 0, 0), (22, 0, 0))\n",
    "    >>> _update_value_owned_by_others([[0,20,30],[40,0,60],[70,80,0]], 0, 0, [[55,66,77],[88,99,11],[22,33,44]])\n",
    "    ((0, 20, 30), (88, 0, 60), (70, 80, 0))\n",
    "    \"\"\"\n",
    "    num_of_agents = len(largest_value_owned_by_others)\n",
    "    new_largest_value_owned_by_others = [\n",
    "        list(d) for d in largest_value_owned_by_others\n",
    "    ]\n",
    "    for other_agent_index in range(num_of_agents):\n",
    "        if other_agent_index == agent_index:\n",
    "            continue\n",
    "        other_agent_value = valuation_matrix[other_agent_index][item_index]\n",
    "        if efx:\n",
    "            replace_item = (\n",
    "                other_agent_value\n",
    "                < new_largest_value_owned_by_others[other_agent_index][\n",
    "                    agent_index\n",
    "                ]\n",
    "            )\n",
    "        else:  # ef1\n",
    "            replace_item = (\n",
    "                other_agent_value\n",
    "                > new_largest_value_owned_by_others[other_agent_index][\n",
    "                    agent_index\n",
    "                ]\n",
    "            )\n",
    "        if replace_item:\n",
    "            new_largest_value_owned_by_others[other_agent_index][\n",
    "                agent_index\n",
    "            ] = other_agent_value\n",
    "    new_largest_value_owned_by_others = tuple(\n",
    "        (tuple(d) for d in new_largest_value_owned_by_others)\n",
    "    )\n",
    "    return new_largest_value_owned_by_others\n",
    "\n",
    "#####\n",
    "## UM within PROP1 Code\n",
    "####\n",
    "\n",
    "def utilitarian_prop1_value(valuation_matrix, propx=False):\n",
    "    \"\"\"\n",
    "    Returns the maximum utilitarian value in a PROP1 allocation - does *not* return the partition itself.\n",
    "    >>> utilitarian_prop1_value([[11,0,11],[33,44,55]])\n",
    "    132\n",
    "    >>> utilitarian_prop1_value([[11,0,11],[33,44,55]],propx=True)\n",
    "    110\n",
    "    >>> utilitarian_prop1_value([[11,22,33,44],[44,33,22,11]])\n",
    "    154\n",
    "    >>> utilitarian_prop1_value([[11,22,33,44],[44,33,22,11]],propx=True)\n",
    "    154\n",
    "    >>> utilitarian_prop1_value([[11,0,11,11],[0,11,11,11],[33,33,33,33]])\n",
    "    132\n",
    "    >>> utilitarian_prop1_value([[11,0,11,11],[0,11,11,11],[33,33,33,33]],propx=True)\n",
    "    88\n",
    "    >>> utilitarian_prop1_value([[11],[22]]) \n",
    "    22\n",
    "    >>> utilitarian_prop1_value([[11],[22]],propx=True)\n",
    "    22\n",
    "    \"\"\"\n",
    "    items = items_as_value_vectors(valuation_matrix)\n",
    "    return PROP1PartitionDP(valuation_matrix, propx).max_value(items)\n",
    "\n",
    "\n",
    "def utilitarian_prop1_allocation(valuation_matrix, propx=False):\n",
    "    \"\"\"\n",
    "    Returns the utilitarian-maximum PROP1 allocation and its utilitarian value.\n",
    "    >>> dynprog.sequential.logger.setLevel(logging.WARNING)\n",
    "    >>> utilitarian_prop1_allocation([[11,0,11],[33,44,55]])\n",
    "    (132, [[], [0, 1, 2]])\n",
    "    >>> utilitarian_prop1_allocation([[11,0,11],[33,44,55]], propx=True)\n",
    "    (110, [[0], [1, 2]])\n",
    "    >>> utilitarian_prop1_allocation([[11,22,33,44],[44,33,22,11]])\n",
    "    (154, [[2, 3], [0, 1]])\n",
    "    >>> utilitarian_prop1_allocation([[11,22,33,44],[44,33,22,11]], propx=True)\n",
    "    (154, [[2, 3], [0, 1]])\n",
    "    >>> utilitarian_prop1_allocation([[11,0,11,11],[0,11,11,11],[33,33,33,33]])\n",
    "    (132, [[], [], [0, 1, 2, 3]])\n",
    "    >>> utilitarian_prop1_allocation([[11,0,11,11],[0,11,11,11],[33,33,33,33]], propx=True)\n",
    "    (88, [[3], [2], [0, 1]])\n",
    "    >>> utilitarian_prop1_allocation([[11],[22]]) \n",
    "    (22, [[], [0]])\n",
    "    >>> utilitarian_prop1_allocation([[11],[22]], propx=True)\n",
    "    (22, [[], [0]])\n",
    "    >>> utilitarian_prop1_allocation([[37,20,34,12,71,17,55,97,79],[57,5,59,63,92,23,4,36,69],[16,3,41,42,68,47,60,39,17]])\n",
    "    (574, [[1, 7, 8], [0, 2, 3, 4], [5, 6]])\n",
    "    >>> utilitarian_prop1_allocation([[37,20,34,12,71,17,55,97,79],[57,5,59,63,92,23,4,36,69],[16,3,41,42,68,47,60,39,17]], propx=True)\n",
    "    (557, [[7, 8], [0, 2, 3, 4], [1, 5, 6]])\n",
    "    \"\"\"\n",
    "    items = items_as_value_vectors(valuation_matrix)\n",
    "    (best_state,best_value,best_solution,num_of_states) = PROP1PartitionDP(valuation_matrix, propx).max_value_solution(items)\n",
    "    if best_value==-math.inf:\n",
    "        raise ValueError(\"No proportional allocation\")\n",
    "    return (best_value,best_solution)\n",
    "\n",
    "\n",
    "\n",
    "#### Dynamic program definition:\n",
    "\n",
    "class PROP1PartitionDP(SequentialDynamicProgram):\n",
    "\n",
    "    # The states are of the form  (v1, v2, ..., vn; b1, b2, ..., bn) where n is the number of agents.\n",
    "    # The \"vi\" are the value of bundle i to agent i.\n",
    "    # The \"bi\" are the largest value for i of an item allocated to others.\n",
    "\n",
    "    def __init__(self, valuation_matrix, propx=False):\n",
    "        num_of_agents = self.num_of_agents = len(valuation_matrix)\n",
    "        self.thresholds = [sum(valuation_matrix[i])/num_of_agents for i in range(num_of_agents)]\n",
    "        self.valuation_matrix = valuation_matrix\n",
    "        self.propx = propx\n",
    "\n",
    "    def initial_states(self):\n",
    "        zero_values = self.num_of_agents*(0,)\n",
    "        initial_value_to_remove = math.inf if self.propx else 0\n",
    "        largest_value_owned_by_others = self.num_of_agents*(initial_value_to_remove,)\n",
    "        yield (zero_values, largest_value_owned_by_others)\n",
    "\n",
    "    def initial_solution(self):\n",
    "        empty_bundles = [ [] for _ in range(self.num_of_agents)]\n",
    "        return empty_bundles\n",
    "   \n",
    "    def transition_functions(self):\n",
    "        return [\n",
    "            lambda state, input, agent_index=agent_index: \\\n",
    "                (add_input_to_agent_value(state[0], agent_index, input) , \\\n",
    "                _PROP1_update_value_owned_by_others(state[1], agent_index, input[-1], self.valuation_matrix, self.propx) )\n",
    "            for agent_index in range(self.num_of_agents)\n",
    "        ]\n",
    "\n",
    "    def construction_functions(self):\n",
    "        return [\n",
    "            lambda solution,input,agent_index=agent_index: add_input_to_bin(solution, agent_index, input[-1])\n",
    "            for agent_index in range(self.num_of_agents)\n",
    "        ]\n",
    "\n",
    "    def value_function(self):\n",
    "        return lambda state: sum(state[0]) if self._is_prop1(state[0], state[1]) else -math.inf\n",
    "    \n",
    "    def _is_prop1(self, bundle_values:list,largest_value_owned_by_others:list)->bool:\n",
    "        return all([bundle_values[i] + largest_value_owned_by_others[i] >= self.thresholds[i] for i in range(self.num_of_agents)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _PROP1_update_value_owned_by_others(largest_value_owned_by_others:list, agent_index:int, item_index:int, valuation_matrix, propx=False):\n",
    "    \"\"\"\n",
    "    :param input: a list of values: input[i] represents the value of the current item for agent i.\n",
    "    Adds the given item to agent #agent_index.\n",
    "    >>> _update_value_owned_by_others([33, 44, 66], 0, 0, [[55,66,77],[88,99,11],[22,33,44]])\n",
    "    (33, 88, 66)\n",
    "    \"\"\"\n",
    "    logger.info(largest_value_owned_by_others)\n",
    "    new_largest_value_owned_by_others = list(largest_value_owned_by_others)\n",
    "    num_of_agents = len(largest_value_owned_by_others)\n",
    "    for other_agent_index in range(num_of_agents):\n",
    "        if other_agent_index!=agent_index:\n",
    "            other_agent_value = valuation_matrix[other_agent_index][item_index]\n",
    "            if propx:\n",
    "                should_replace_item = other_agent_value < new_largest_value_owned_by_others[other_agent_index]\n",
    "            else: # prop1\n",
    "                should_replace_item = other_agent_value > new_largest_value_owned_by_others[other_agent_index]\n",
    "            if should_replace_item:\n",
    "                new_largest_value_owned_by_others[other_agent_index] = other_agent_value\n",
    "    return tuple(new_largest_value_owned_by_others)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valuation_matrix:\n",
      " [[8 6 0 4 8 5 2 0 4 8]\n",
      " [8 5 0 4 8 4 7 7 8 7]\n",
      " [2 2 3 0 8 6 0 5 7 1]]\n",
      "Utilitarian within EF1:  65.0\n",
      "Valuation matrix:\n",
      " [[11 60 41 81 74 96 79]\n",
      " [41 30 58 59 64 24 86]\n",
      " [55 54 45 13 78 17 92]]\n",
      "Utilitarian PROP1 value: 520\n",
      "Utilitarian PROP1 allocation: (520, [[1, 3, 5], [2], [0, 4, 6]])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "valuation_matrix = np.random.randint(0,9, [3,10])\n",
    "print(\"valuation_matrix:\\n\", valuation_matrix)\n",
    "print(\"Utilitarian within EF1: \", utilitarian_ef1_value(valuation_matrix))\n",
    "\n",
    "valuation_matrix = np.random.randint(0,99, [3,7])   # ~ 3000 states\n",
    "print(\"Valuation matrix:\\n\",valuation_matrix)\n",
    "print(\"Utilitarian PROP1 value:\",utilitarian_prop1_value(valuation_matrix))\n",
    "print(\"Utilitarian PROP1 allocation:\",utilitarian_prop1_allocation(valuation_matrix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
